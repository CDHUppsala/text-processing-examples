{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7d92f2",
   "metadata": {},
   "source": [
    "# Literary style\n",
    "\n",
    "A notebook for \"Case Study 2: Literary Style\" in Gijs Aangenendt, Maria Skeppstedt & Karl Berglund (2025), \"Applied NLP for Humanities Research\", in XXXX.\n",
    "\n",
    "Code written by Karl Berglund."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ee6c4",
   "metadata": {},
   "source": [
    "# 0. PREPARATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbced8",
   "metadata": {},
   "source": [
    "### 0.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5224b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #for working with dataframes\n",
    "import glob #for grabbing multiple files\n",
    "import seaborn as sns #for making plots\n",
    "import matplotlib.pyplot as plt #for making plots\n",
    "from scipy.stats import linregress #for linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a288b",
   "metadata": {},
   "source": [
    "### 0.2 Import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('/PathToFile/literary_style.csv') #insert path to metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb02602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out the dataframe\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd3ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00886c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2e2a8",
   "metadata": {},
   "source": [
    "### 0.3 Import corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f853a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of all the files in the path\n",
    "text_files = glob.glob(f\"/Users/karbe804/Desktop/literary_style/*.conll\") #path to folder\n",
    "text_files = sorted(text_files) #sort list to keep alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e0f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out paths to corpus\n",
    "text_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a434a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f29a09",
   "metadata": {},
   "source": [
    "# 1. PUNCTUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444269cb",
   "metadata": {},
   "source": [
    "### 1.1 Calculate punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae348e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose punctuation, here semicolon\n",
    "chosen_punctuation = \";\"\n",
    "\n",
    "#create empty variables to fill\n",
    "chosen_punctuation_rel = []\n",
    "tokens_total = []\n",
    "\n",
    "for file_path in text_files: #loop over all novels in corpus (each path in the list of paths)\n",
    "    \n",
    "    #parse text data to pandas dataframe\n",
    "    #note: pandas automatically deletes blank rows\n",
    "    text_data = pd.read_csv(file_path, sep=\"\\t\", names=[\"token\", \"ling\",\"POS\",\"lemma\"])\n",
    "    \n",
    "    #create two counters: one for all tokens, one for chosen punctuation\n",
    "    tokens = 0\n",
    "    punctuation = 0\n",
    "    \n",
    "    for token in text_data[\"token\"]: #loop over all tokens in novel\n",
    "        \n",
    "        if not token == \"PARAGRAPH_BREAK\": #don't count paragraph breaks as tokens\n",
    "            tokens += 1 #count token\n",
    "            \n",
    "            if token == chosen_punctuation: #set if condition for only the chosen punctuation\n",
    "                punctuation += 1 #count chosen punctuation  \n",
    "                \n",
    "   \n",
    "    rel_freqs = punctuation/tokens #calculate relative frequencies of chosen punctuation\n",
    "    \n",
    "    #append results to lists\n",
    "    chosen_punctuation_rel.append(rel_freqs)\n",
    "    tokens_total.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e883745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add lists as variables to metadata dataframe\n",
    "metadata[\"tokens\"] = tokens_total\n",
    "metadata[\"semicolons_rel\"] = chosen_punctuation_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out dataframe with the added column\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"tokens\"].sum() #check total amount of tokens in corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2df12",
   "metadata": {},
   "source": [
    "### 1.2 Make bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5)) #set size of figure\n",
    "\n",
    "metric_to_plot = \"semicolons_rel\" #choose metric to plot\n",
    "\n",
    "#sort data descending according to metric in use\n",
    "sorted_data = metadata.sort_values(metric_to_plot, ascending=False)\n",
    "\n",
    "#create labels for legend\n",
    "new_labels = ['Canonized authors \\nwithout large readerships', \n",
    "              'Canonized authors \\nwith large readerships', \n",
    "              'Popular genre fiction authors \\nwith large readerships']  \n",
    "\n",
    "#set order for legend\n",
    "order = ['kanon', 'kanon_publ','publik']\n",
    "\n",
    "#make a bar plot per novel for the chosen metric and with the specified legend order\n",
    "barplot = sns.barplot(x=sorted_data[\"Title\"], y=sorted_data[metric_to_plot],\n",
    "            hue=sorted_data[\"Category\"], dodge=False, hue_order=order)\n",
    "\n",
    "#generate xticks labels through a loop\n",
    "xticks_labels = []\n",
    "for i in sorted_data.index:\n",
    "    xticks_labels.append(sorted_data[\"Author\"][i]+\" – \"+sorted_data[\"Title\"][i]) #\"author – title\"\n",
    "\n",
    "#use and specify xticks\n",
    "plt.xticks(ticks=range(len(sorted_data[\"Title\"])), labels=xticks_labels, rotation=90, size=6)\n",
    "\n",
    "#specify axes labels \n",
    "plt.ylabel(metric_to_plot)\n",
    "plt.xlabel(None) #here the xticks provide enough information\n",
    "\n",
    "#set legends to bar plot\n",
    "handles, labels = barplot.get_legend_handles_labels()\n",
    "\n",
    "#plot figure\n",
    "plt.legend(handles, new_labels, loc='upper right', bbox_to_anchor=(1, 1)) \n",
    "\n",
    "#export figure, set file path to where you want to place the file\n",
    "plt.savefig(\"/yourpath/pyplot.png\", format='png', dpi=300, bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6226d",
   "metadata": {},
   "source": [
    "# 2. SENTENCES AND PARAGRAPHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f322c",
   "metadata": {},
   "source": [
    "### 2.1 Calculate sentence and paragraph lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty variables to fill\n",
    "sentence_length_mean = []\n",
    "paragraph_length_mean = []\n",
    "\n",
    "for file_path in text_files: #loop over all novels in corpus (each path in the list of paths)\n",
    "    \n",
    "    #parse text data to pandas dataframe\n",
    "    #note: pandas automatically deletes blank rows\n",
    "    text_data = pd.read_csv(file_path, sep=\"\\t\", names=[\"token\", \"ling\",\"POS\",\"lemma\"])\n",
    "    \n",
    "    #create three counters: one for all tokens, one for paragraph breaks, one for major delimiters\n",
    "    tokens = 0\n",
    "    paragraph_breaks = 0\n",
    "    major_delimiters = 0\n",
    "    \n",
    "    for token in text_data[\"token\"]: #loop over all tokens in novel\n",
    "        \n",
    "        if not token == \"PARAGRAPH_BREAK\": #don't count paragraph breaks as tokens\n",
    "            tokens += 1 #count token\n",
    "        \n",
    "        else:\n",
    "            paragraph_breaks += 1 #count paragraph break\n",
    "    \n",
    "    for ling in text_data[\"ling\"]: #loop over second column in dataframe, with info about delimiters\n",
    "        if ling == \"MAD\": #set if condition for counting only major delimiters (\"MAD\")\n",
    "            major_delimiters += 1 #count major delimiter\n",
    "                \n",
    "   \n",
    "    paragraph_len = tokens/paragraph_breaks #calculate average paragraph length\n",
    "    sentence_len = tokens/major_delimiters #calculate average sentence length\n",
    "    \n",
    "    #append results to lists\n",
    "    paragraph_length_mean.append(paragraph_len)\n",
    "    sentence_length_mean.append(sentence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add lists as columns to metadata dataframe\n",
    "metadata[\"paragraph_mean\"] = paragraph_length_mean\n",
    "metadata[\"sents_mean\"] = sentence_length_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out dataframe with added columns\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f6347",
   "metadata": {},
   "source": [
    "### 2.2 Make scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88aa08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5)) #set size of figure\n",
    "\n",
    "#set values for scatter plot\n",
    "x_value = \"sents_mean\"\n",
    "y_value = \"paragraph_mean\"\n",
    "\n",
    "#create new labels for legend\n",
    "new_labels = ['Canonized authors \\nwithout large readerships', \n",
    "              'Canonized authors \\nwith large readerships', \n",
    "              'Popular genre fiction authors \\nwith large readerships']  \n",
    "\n",
    "#set order for legend\n",
    "order = ['kanon', 'kanon_publ','publik']\n",
    "\n",
    "\n",
    "#make a scatter plot per novel for the chosen metrics and with the specified legend order\n",
    "scatterplot = sns.scatterplot(x=metadata[x_value], y=metadata[y_value],\n",
    "            hue=metadata[\"Category\"], hue_order=order)\n",
    "\n",
    "#set axes labels\n",
    "plt.xlabel(\"Mean sentence length (tokens)\")\n",
    "plt.ylabel(\"Mean paragraph length (tokens)\")\n",
    "\n",
    "#set legend to scatter plot\n",
    "handles, labels = scatterplot.get_legend_handles_labels()\n",
    "\n",
    "#plot figure\n",
    "plt.legend(handles, new_labels, loc='lower right')\n",
    "\n",
    "# plot authors and titles for novels\n",
    "for i in range(len(metadata)):\n",
    "    x_offset = 0.3 #this offset is to make graph prettier\n",
    "    y_offset = 0\n",
    "    \n",
    "    # plot only certain outliers\n",
    "    list_of_exceptions = [\"Enhörningarna\", \"De dömdas ö\", \"Chitambo\",\"Chefen fru Ingeborg\", \n",
    "                          \"Kvinnan och nåden\",\"Guds vackra värld I–II\",\"Pennskaftet\"]\n",
    "    \n",
    "    if metadata[\"Title\"].iloc[i] in list_of_exceptions: #conditional statement\n",
    "    \n",
    "        plt.text(x=metadata[x_value].iloc[i] + x_offset,\n",
    "                 y=metadata[y_value].iloc[i] + y_offset,\n",
    "                 s=metadata[\"Author\"].iloc[i]+\" - \"+metadata[\"Title\"].iloc[i], #\"author – title\"\n",
    "                 fontdict=dict(color=\"black\", size=4))\n",
    "    \n",
    "#export figure, set file path to where you want to place the file\n",
    "plt.savefig(\"/yourpath/pyplot.png\", format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348bd026",
   "metadata": {},
   "source": [
    "### 2.3 Calculate mean scores on group level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create subsets on group levels\n",
    "canon = metadata[metadata[\"Category\"] == \"kanon\"]\n",
    "canon_publ = metadata[metadata[\"Category\"] == \"kanon_publ\"]\n",
    "popular = metadata[metadata[\"Category\"] == \"publik\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ecd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate sentence mean scores per subset\n",
    "print(canon[\"sents_mean\"].mean(),canon_publ[\"sents_mean\"].mean(),popular[\"sents_mean\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate paragraph mean scores per subset\n",
    "print(canon[\"paragraph_mean\"].mean(),canon_publ[\"paragraph_mean\"].mean(),popular[\"paragraph_mean\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50feca5",
   "metadata": {},
   "source": [
    "# 3. PARTS OF SPEECH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d57ebaf",
   "metadata": {},
   "source": [
    "### 3.1 Calculate parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists to fill\n",
    "adjs_rel_list = []\n",
    "verbs_rel_list = []\n",
    "\n",
    "for file_path in text_files: #loop over all novels in corpus (each path in the list of paths)\n",
    "    \n",
    "    #parse text data to pandas dataframe\n",
    "    #note: pandas automatically deletes blank rows\n",
    "    text_data = pd.read_csv(file_path, sep=\"\\t\", names=[\"token\", \"ling\",\"POS\",\"lemma\"])\n",
    "    \n",
    "    #strip all paragraph breaks\n",
    "    red_text_data = text_data[text_data[\"token\"] != \"PARAGRAPH_BREAK\"]\n",
    "    \n",
    "    tokens = len(red_text_data) #everything in orig csv except blanks and paragraph breaks ==> tokens\n",
    "    \n",
    "    #create two counters: one for adjectives, one for verbs\n",
    "    adjectives = 0\n",
    "    verbs = 0\n",
    "    \n",
    "    for POS in red_text_data[\"POS\"]: #loop over third column in dataframe, with info about parts of speech\n",
    "        if POS == \"ADJ\": #conditional statement for counting only adjectives\n",
    "            adjectives += 1 #count adjectives\n",
    "        elif POS == \"VERB\": #conditional statement for counting only verbs\n",
    "            verbs += 1 #count verbs\n",
    "                \n",
    "    adjectives_rel = adjectives/tokens #calculate average paragraph length\n",
    "    verbs_rel = verbs/tokens #calculate average sentence length\n",
    "    \n",
    "    #append results to lists\n",
    "    adjs_rel_list.append(adjectives_rel)\n",
    "    verbs_rel_list.append(verbs_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add lists as columns to metadata dataframe\n",
    "metadata[\"adjs_rel\"] = adjs_rel_list\n",
    "metadata[\"verbs_rel\"] = verbs_rel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee26944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out dataframe with added columns\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6447c0e2",
   "metadata": {},
   "source": [
    "### 3.2 Make scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d72b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5)) #set size of figure\n",
    "\n",
    "#set values for scatter plot\n",
    "x_value = \"verbs_rel\"\n",
    "y_value = \"adjs_rel\"\n",
    "\n",
    "#create new labels for legend\n",
    "new_labels = ['Canonized authors \\nwithout large readerships', \n",
    "              'Canonized authors \\nwith large readerships', \n",
    "              'Popular genre fiction authors \\nwith large readerships']  \n",
    "\n",
    "#set order for legend\n",
    "order = ['kanon', 'kanon_publ','publik']\n",
    "\n",
    "#make a scatter plot per novel for the chosen metrics and with the specified legend order\n",
    "scatterplot = sns.scatterplot(x=metadata[x_value], y=metadata[y_value],\n",
    "            hue=metadata[\"Category\"], hue_order=order)\n",
    "\n",
    "#set axes labels\n",
    "plt.xlabel(\"Verbs (share)\")\n",
    "plt.ylabel(\"Adjectives (share)\")\n",
    "\n",
    "#set legend to scatter plot\n",
    "handles, labels = scatterplot.get_legend_handles_labels()\n",
    "\n",
    "#add regression line\n",
    "sns.regplot(x=metadata[x_value], y=metadata[y_value], scatter=False, color=\"red\", \n",
    "            line_kws={'linewidth': 1, 'alpha': 0.3})\n",
    "\n",
    "#add axes labels\n",
    "plt.xlabel(\"Verbs (share)\")\n",
    "plt.ylabel(\"Adjectives (share)\")\n",
    "\n",
    "# plot authors and titles for novels\n",
    "for i in range(len(metadata)):\n",
    "    x_offset = 0.0005 #this offset is to make graph prettier\n",
    "    y_offset = 0\n",
    "    \n",
    "    # plot only certain outliers\n",
    "    list_of_exceptions = [\"Kvinnan och nåden\", \"Astarte\",\"Chitambo\",\"Kris\",\"Kvartetten som sprängdes\",\n",
    "                         \"Snörmakare Lekholm får en idé\",\"Min död är min\",\"Vingslag i natten\",\n",
    "                          \"Till och från Högåsen\",\"Barmhärtighet\",\n",
    "                         \"Kejsarn av Portugallien\",\"På dessa skuldror\",]\n",
    "    \n",
    "    if metadata[\"Title\"].iloc[i] in list_of_exceptions: #conditional statement\n",
    "    \n",
    "        plt.text(x=metadata[x_value].iloc[i] + x_offset,\n",
    "                 y=metadata[y_value].iloc[i] + y_offset,\n",
    "                 s=metadata[\"Author\"].iloc[i]+\" - \"+metadata[\"Title\"].iloc[i], #\"author – title\"\n",
    "                 fontdict=dict(color=\"black\", size=4))\n",
    "\n",
    "#plot figure\n",
    "plt.legend(handles, new_labels, loc='upper right')\n",
    "        \n",
    "#export figure, set file path to where you want to place the file\n",
    "plt.savefig(\"/yourpath/pyplot.png\", format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b5316",
   "metadata": {},
   "source": [
    "### 3.3. Calculate linear regression R value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = linregress(metadata[x_value],metadata[y_value])\n",
    "print(r_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e738453",
   "metadata": {},
   "source": [
    "### 3.4 Calculate means on group level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581bb8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create subsets on group level\n",
    "canon = metadata[metadata[\"Category\"] == \"kanon\"]\n",
    "canon_publ = metadata[metadata[\"Category\"] == \"kanon_publ\"]\n",
    "popular = metadata[metadata[\"Category\"] == \"publik\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be75faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print mean scores of adjectives\n",
    "print(canon[\"adjs_rel\"].mean(),canon_publ[\"adjs_rel\"].mean(),popular[\"adjs_rel\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fad11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print mean scores of verbs\n",
    "print(canon[\"verbs_rel\"].mean(),canon_publ[\"verbs_rel\"].mean(),popular[\"verbs_rel\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a2f3c",
   "metadata": {},
   "source": [
    "# 4. WRITE CSV-FILE INCLUDING ADDED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/yourpath/literary_style_added.csv\", \"w\") as file:\n",
    "    metadata.to_csv(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
